{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n@Author: Vighnesh Harish Bilgi\\n@Date: 2022-11-25\\n@Last Modified by: Vighnesh Harish Bilgi\\n@Last Modified time: 2022-11-25\\n@Title : Genrerate random records and upload them to dynamoDB\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "@Author: Vighnesh Harish Bilgi\n",
    "@Date: 2022-11-25\n",
    "@Last Modified by: Vighnesh Harish Bilgi\n",
    "@Last Modified time: 2022-11-25\n",
    "@Title : Genrerate random records and upload them to dynamoDB\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import names\n",
    "import random\n",
    "import time\n",
    "# import \n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.environ.get('test1_access_key')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.environ.get('test1_secret_access_key')\n",
    "TABLE_NAME = 'Auto_Load_Table'\n",
    "BUCKET_NAME = 'auto-load-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom fucntions to create dynamoDB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_dynamoDB():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS DynamoDB service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource dyDB\n",
    "\n",
    "    \"\"\"\n",
    "    dyDB =  boto3.resource('dynamodb')\n",
    "    return dyDB\n",
    "\n",
    "def create_items(table,dataset_records):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To create items in a table of DynamoDB.\n",
    "    Parameter:\n",
    "        dynamodb.table table\n",
    "    Return:\n",
    "        No values returned.\n",
    "\n",
    "    \"\"\"\n",
    "    table.put_item(\n",
    "        Item={\n",
    "                'id': dataset_records[0],\n",
    "                'name': dataset_records[1]\n",
    "            }\n",
    "    )\n",
    "\n",
    "def create_table(dyDB,table_name):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To create a dynamoDB table if it doen't exist\n",
    "    Parameter:\n",
    "        ServiceResource dyDB\n",
    "    Return:\n",
    "        no value returned\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    dynamodb_client = boto3.client('dynamodb')\n",
    "    existing_tables = dynamodb_client.list_tables()['TableNames']\n",
    "\n",
    "    if table_name not in existing_tables:\n",
    "        # Create the DynamoDB table.\n",
    "        dyDB.create_table(\n",
    "            TableName=table_name,\n",
    "            KeySchema=[\n",
    "                {\n",
    "                    'AttributeName': 'id',\n",
    "                    'KeyType': 'HASH'\n",
    "                },\n",
    "                {\n",
    "                    'AttributeName': 'name',\n",
    "                    'KeyType': 'RANGE'\n",
    "                }\n",
    "            ],\n",
    "            AttributeDefinitions=[\n",
    "                {\n",
    "                    'AttributeName': 'id',\n",
    "                    'AttributeType': 'N'\n",
    "                },\n",
    "                {\n",
    "                    'AttributeName': 'name',\n",
    "                    'AttributeType': 'S'\n",
    "                },\n",
    "            ],\n",
    "            ProvisionedThroughput={\n",
    "                'ReadCapacityUnits': 5,\n",
    "                'WriteCapacityUnits': 5\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom fucntions to connect to S3 resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3_client():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "\n",
    "def connect_to_s3_resource():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3')\n",
    "    return s3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom fucntions to create upload data to DynamoDB and send each item from DynamoDB as .csv file to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_upload(table,n):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        Generating 'n' records of 'id' and 'name' \n",
    "        where random 5 digit integers as id and \n",
    "        random names from 'names' module and uploading them to dynamoDB Table 'table'\n",
    "    Parameter:\n",
    "        dynamodb.table table,\n",
    "        integer n\n",
    "    Return:\n",
    "        No values returned\n",
    "        \n",
    "    \"\"\"\n",
    "    print(f\"Entering records into DynamoDB Table '{TABLE_NAME}' ...\")\n",
    "    for i in range(n):\n",
    "        \n",
    "        record = [random.randint(10000,99999), names.get_full_name()]\n",
    "        print(f\"Record #{i+1} data : {record}\")\n",
    "        create_items(table,record)\n",
    "\n",
    "        # wait for 5 seconds before next iteration\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "def dynamo_to_s3(table):\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        Fetching each item from dynamoDB Table 'table' as .csv file and uploading them to S3 bucket\n",
    "    Parameter:\n",
    "        dynamodb.table table\n",
    "    Return:\n",
    "        No values returned\n",
    "\n",
    "    \"\"\"\n",
    "    s3 = connect_to_s3_resource()\n",
    "    \n",
    "    table_details = table.scan()\n",
    "    table_items = table_details['Items']\n",
    "\n",
    "    print(f\"Displaying objects in {BUCKET_NAME}:\")\n",
    "\n",
    "    count = 1\n",
    "    for item in table_items:\n",
    "\n",
    "        file_name = f'record#{count}.csv'\n",
    "\n",
    "        csv_buffer = StringIO()\n",
    "        df = pd.DataFrame(item, index=[0]) \n",
    "        df.to_csv(csv_buffer, index= False)\n",
    "        s3.Object(BUCKET_NAME, f'data-output/{file_name}').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "        print(f\"{file_name} is uploaded to S3 Bucket '{BUCKET_NAME}'\")\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "        # wait for 30 seconds before next iteration\n",
    "        time.sleep(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all bucket names to verify if - auto-load-bucket is created:\n",
      "athena-dynamo-output\n",
      "auto-load-bucket\n",
      "aws-glue-assets-949401335332-us-east-1\n",
      "aws-logs-949401335332-us-east-1\n",
      "body-parquet\n",
      "dataset-athena-bucket\n",
      "dataset-input-bucket\n",
      "output-stream-bucket\n",
      "parquet-bukcet\n",
      "redshift-dataset-input\n",
      "redshift-twitter-input-bucket\n",
      "title-parquet\n",
      "twitter-streaming-output-bucket\n"
     ]
    }
   ],
   "source": [
    "s3 = connect_to_s3_resource()\n",
    "client = connect_to_s3_client()\n",
    "\n",
    "# creating new bucket\n",
    "client.create_bucket(Bucket = BUCKET_NAME,ACL = 'public-read-write')\n",
    "print(f\"Printing all bucket names to verify if - {BUCKET_NAME} is created:\")\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Send data to DynamoDB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime creation of Table : 2022-12-01 10:28:00.795000+05:30\n",
      "Entering records into DynamoDB Table 'Auto_Load_Table' ...\n",
      "Record #1 data : [90426, 'Fernando Sloss']\n",
      "Record #2 data : [95188, 'Patrick Piper']\n",
      "Record #3 data : [55209, 'Justine Williams']\n",
      "Record #4 data : [85452, 'Latrice Jamal']\n",
      "Record #5 data : [76609, 'Dianne Taylor']\n",
      "Record #6 data : [11601, 'Jesse Presswood']\n",
      "Record #7 data : [36731, 'Jayson Bosch']\n",
      "Record #8 data : [72019, 'Timothy Dwyer']\n",
      "Record #9 data : [52358, 'Anita Schneider']\n",
      "Record #10 data : [39418, 'Courtney Demma']\n",
      "Record #11 data : [74844, 'Michael Luff']\n",
      "Record #12 data : [90338, 'Joyce Kopecky']\n",
      "Record #13 data : [62148, 'Lynn Watson']\n",
      "Record #14 data : [76048, 'Flora Akers']\n",
      "Record #15 data : [22638, 'Betty Berry']\n",
      "Record #16 data : [90727, 'Paul Conley']\n",
      "Record #17 data : [23344, 'Daniel Garcia']\n",
      "Record #18 data : [11069, 'Neal Carlos']\n",
      "Record #19 data : [13880, 'Jean Janousek']\n",
      "Record #20 data : [57730, 'Josephine Hampton']\n"
     ]
    }
   ],
   "source": [
    "dyDB = connect_to_dynamoDB()\n",
    "\n",
    "create_table(dyDB,TABLE_NAME)\n",
    "\n",
    "table = dyDB.Table(TABLE_NAME)\n",
    "table.wait_until_exists()\n",
    "print(f\"DateTime creation of Table : {table.creation_date_time}\")\n",
    "\n",
    "n = int(input(\"Enter number of times to run loop:\"))\n",
    "\n",
    "generate_and_upload(table,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Send items from DynamoDB Table as .csv file to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying objects in auto-load-bucket:\n",
      "record#1.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#2.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#3.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#4.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#5.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#6.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#7.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#8.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#9.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#10.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#11.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#12.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#13.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#14.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#15.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#16.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#17.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#18.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#19.csv is uploaded to S3 Bucket 'auto-load-bucket'\n",
      "record#20.csv is uploaded to S3 Bucket 'auto-load-bucket'\n"
     ]
    }
   ],
   "source": [
    "table = dyDB.Table(TABLE_NAME)\n",
    "dynamo_to_s3(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
